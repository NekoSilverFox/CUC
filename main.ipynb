{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据集（具有正态分布的）\n",
    "x_1_1 = pd.Series(np.random.normal(loc=22, scale=4, size=50), name='x1')\n",
    "x_1_2 = pd.Series(np.random.normal(loc=24, scale=4, size=50), name='x2')\n",
    "y_1 = pd.Series(['blue'] * 50, name='target')\n",
    "\n",
    "x_2_1 = pd.Series(np.random.normal(loc=8, scale=3, size=50), name='x1')\n",
    "x_2_2 = pd.Series(np.random.normal(loc=12, scale=3, size=50), name='x2')\n",
    "y_2 = pd.Series(['red'] * 50, name='target')\n",
    "\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "plt.scatter(x_1_1, x_1_2, c='blue')\n",
    "plt.scatter(x_2_1, x_2_2, c='red')\n",
    "plt.show()\n",
    "\n",
    "tmp_data_1 = pd.concat([x_1_1, x_1_2, y_1], axis=1)\n",
    "tmp_data_2 = pd.concat([x_2_1, x_2_2, y_2], axis=1)\n",
    "data = pd.concat([tmp_data_1, tmp_data_2], axis=0)\n",
    "data = shuffle(data).reset_index(drop=True)  # 打乱样本顺序\n",
    "\n",
    "# 划分数据集\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.iloc[:, :-1], data.iloc[:, -1])\n",
    "\n",
    "# 归一化\n",
    "transfer = MinMaxScaler(feature_range=(0, 10))\n",
    "x_train = transfer.fit_transform(X=x_train)\n",
    "x_test = transfer.transform(X=x_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUC 的主类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------*------ coding: utf-8 ------*------\n",
    "# @Time    : 2023/3/27 18:45\n",
    "# @Author  : 冰糖雪狸 (NekoSilverfox)\n",
    "# @Project : CUC\n",
    "# @File    : CodingUnitClassifier.py\n",
    "# @Software: PyCharm\n",
    "# @Github  ：https://github.com/NekoSilverFox\n",
    "# -----------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class CodingUnitClassifier(object):\n",
    "    \"\"\"编码单元分类器预估器（estimator）\"\"\"\n",
    "    class CUType(Enum):\n",
    "        NOT_FINAL_CU = -1\n",
    "        EMPTY_CU = -2\n",
    "\n",
    "    def __init__(self, num_refinement_splits=0, threshold_value=1.0, is_draw_2D=False, color_map=[], pic_save_path=None, **kw) -> None:\n",
    "        \"\"\"初始化\n",
    "\n",
    "        Args:\n",
    "            num_refinement_splits (int, optional): 细化分割次数. Defaults to 0.\n",
    "            threshold_value (int, optional): 临界值. Defaults to  1.0.\n",
    "            is_draw_2D (bool, optional): 当绘制 2D 数据集，是否绘制中途图像. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.is_draw_2D = is_draw_2D\n",
    "        self.pic_save_path = pic_save_path\n",
    "        self.color_map = color_map\n",
    "        self.draw_count = 0  # 绘制次数记录（还用于拓展保存时的文件名）\n",
    "\n",
    "        self.split_count = 0  # 分割次数计数器\n",
    "        self.num_refinement_splits = num_refinement_splits\n",
    "        self.threshold_value = threshold_value  # 临界值：当某个 CU 中某种粒子占比超过这个阈值，则暂停分割\n",
    "\n",
    "        self.transfer_LabelEncoder = None  # 目标值的转换器（转为数字）\n",
    "\n",
    "        self.N_train = None  # 训练集的维度\n",
    "        self.X_train = None  # 特征值（训练集）\n",
    "        self.y_train = None  # 目标值（训练集）\n",
    "        self.df_train = None  # 以 pandas.DataFream 形式的训练接数据（特征值和训练集是合并在一起的）。目标值的索引为 `target`，特征值的索引为 `x`，x 为从 0 开始的数字\n",
    "\n",
    "        self.CU_min = None  # 编码单元范围最小值\n",
    "        self.CU_max = None  # 编码单元范围最小值\n",
    "\n",
    "        self.arrCU_start_points = None  # 编码单元起始点列表\n",
    "        self.arrCU_dL = None  # arrCU_start_points 对应位置的编码单元的边长 `dL`\n",
    "        self.arrCU_is_enable = None  # arrCU_start_points 对应位置的编码单元是否启用，True 代表启用，False 代表不启用\n",
    "        self.arrCU_final_target = None  # arrCU_start_points 对应位置的编码单元的最终预测类别（-1 代表无类别）\n",
    "        self.arrCU_force_infection = None  # arrCU_start_points 对应位置的编码单元的感染力度 (force of infection)\n",
    "\n",
    "    def arr_checker(self):\n",
    "        \"\"\"\n",
    "        检测当前 self 内数组的长度是否正常\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.arrCU_start_points.shape[0] != self.arrCU_dL.shape[0] != self.arrCU_is_enable.shape[0] != \\\n",
    "                self.arrCU_final_target.shape[0]:\n",
    "            raise ValueError(f'arrCU 长度异常：\\n'\n",
    "                             f'\\t{self.arrCU_start_points.shape[0]}'\n",
    "                             f'\\t{self.arrCU_dL.shape[0]}'\n",
    "                             f'\\t{self.arrCU_is_enable.shape[0]}'\n",
    "                             f'\\t{self.arrCU_final_target.shape[0]}')\n",
    "\n",
    "    def is_point_in_CU(self, point: np.ndarray, start_point: np.ndarray, dL: float) -> bool:\n",
    "        \"\"\"\n",
    "        判断点（样本）point，是否在编码单元中\n",
    "        :param point: 需要判断的点\n",
    "        :param start_point: 编码单元的起始点\n",
    "        :param dL: 编码单元的边长\n",
    "        :return: True-在这个 CU 中；False：不在这个 CU 中\n",
    "        \"\"\"\n",
    "        point = np.array(point)\n",
    "        start_point = np.array(start_point)\n",
    "        end_point = np.array(start_point + dL)  # 结束点\n",
    "        if (point > start_point).all() and (point < end_point).all():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_CU_need_split(self, arr1d_start_points: np.ndarray, dL: np.float) -> np.int:\n",
    "        \"\"\"判断当前 CU 是否需要继续预分割（如果需要返回 -1，如果不需要返回当前 CU 所属的目标值，并且 -2 代表为空白 CU）\n",
    "\n",
    "        Args:\n",
    "            arr1d_start_points (np.ndarray): 当前 CU 的起始点\n",
    "            dL (np.float): 当前 CU 的边长\n",
    "\n",
    "        Raises:\n",
    "            ValueError: _description_\n",
    "            ValueError: _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: True为需要进一步分割，如果不需要返回当前 CU 所属的目标值\n",
    "        \"\"\"\n",
    "        if dL <= 0:\n",
    "            raise ValueError(f'[CUC-ERROR] dl can not <= 0, your dL is {dL}')\n",
    "        if arr1d_start_points.shape[0] != self.N_train:\n",
    "            raise ValueError(\n",
    "                f'[CUC-ERROR] arr1d_start_points.shape not correct: arr1d_start_points.shape is {arr1d_start_points.shape}, '\n",
    "                f'should be ({self.N_train}, )')\n",
    "\n",
    "        s_type_count = pd.Series(index=np.unique(self.y_train)).fillna(value=0)  # 计数器，列索引为类别，对应位置数据为该 CU 中此种类粒子数量\n",
    "\n",
    "        # 遍历判断点是否在这个 CU  中\n",
    "        for col, col_target in zip(self.X_train, self.y_train):  # col_target 为当前行的目标值\n",
    "            # 判断粒子在此维度上是否介于 CU 的起始点和结束点\n",
    "            if self.is_point_in_CU(point=col, start_point=arr1d_start_points, dL=dL):\n",
    "                s_type_count[col_target] += 1\n",
    "\n",
    "        # -1 代表这个编码单元里没有任何粒子，为空白编码单元\n",
    "        if 0 == s_type_count.sum():\n",
    "            return self.CUType.EMPTY_CU.value\n",
    "\n",
    "        # 如果不是空 CU，则看看某种 target 的粒子占比是否达到阈值\n",
    "        s_type_count = s_type_count / s_type_count.sum()  # 转换为概率\n",
    "        if (s_type_count.max() >= self.threshold_value) and \\\n",
    "                (1 == s_type_count[s_type_count.values == s_type_count.max()].shape[0]):  # 不允许出现两种相同概率\n",
    "            return s_type_count[s_type_count.values == s_type_count.max()].index[0]\n",
    "        else:\n",
    "            return self.CUType.NOT_FINAL_CU.value\n",
    "\n",
    "    def split_CU_and_update2arrCU(self, index_start_points: int) -> None:\n",
    "        \"\"\"分割当前 CU，并将分割的结果更新到方法内部成员\n",
    "\n",
    "        Args:\n",
    "            index_start_points (int): 需要分割 CU 的索引\n",
    "        \"\"\"\n",
    "        if not self.arrCU_is_enable[index_start_points]:\n",
    "            raise ValueError(f'[CUC-ERROR] CU on index {index_start_points} already disable, can not continue split')\n",
    "\n",
    "        self.arrCU_is_enable[index_start_points] = False  # 既然对这个单元分割就说明这个单元不再使用了，因为它被差分成了许多新的小单元\n",
    "        # if self.arrCU_is_enable[index_start_points]:\n",
    "        #     print('>>>>>>>>>>>>>>>>>>> ERROR >>>>>>>>>>>>>>>>>>>')\n",
    "\n",
    "        start_points = self.arrCU_start_points[index_start_points]\n",
    "        new_dL = self.arrCU_dL[index_start_points] / 2\n",
    "        end_points = np.array(start_points + new_dL)\n",
    "\n",
    "        # 生成包含所有可能性组合的列表\n",
    "        combinations = []\n",
    "        for i in range(2 ** self.N_train):\n",
    "            new_combination = []\n",
    "            for j in range(self.N_train):\n",
    "                if i & (1 << j):\n",
    "                    new_combination.append(end_points[j])\n",
    "                else:\n",
    "                    new_combination.append(start_points[j])\n",
    "            combinations.append(new_combination)\n",
    "\n",
    "        # print(f'\\n\\n[INFO] -------------split-------------\\n'\n",
    "        #       f'new_dL: {new_dL}\\n'\n",
    "        #       f'new_combination:\\n{combinations}')\n",
    "\n",
    "        # 分割后的 CU 添加至缓冲区\n",
    "        self.arrCU_start_points = np.vstack([self.arrCU_start_points, np.array(combinations)])\n",
    "        self.arrCU_dL = np.hstack([self.arrCU_dL, np.full(shape=(2 ** self.N_train,), fill_value=new_dL)])\n",
    "        self.arrCU_is_enable = np.hstack([self.arrCU_is_enable, np.full(shape=(2 ** self.N_train,), fill_value=True)])\n",
    "        self.arrCU_final_target = np.hstack(\n",
    "            [self.arrCU_final_target,\n",
    "             np.full(shape=(2 ** self.N_train,), fill_value=self.arrCU_final_target[index_start_points], dtype=np.int)])\n",
    "\n",
    "        self.split_count += 1\n",
    "\n",
    "    def remove_disable_points(self):\n",
    "        \"\"\"\n",
    "        删除 arr 群组中 disable 的 point\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 移除 self arr 数组群中 disable 的 CU，\n",
    "        # 同时重新标记细化分割中产生的新空白 CU（原含有粒子的大 CU 被重新切分后可能会产生不包含粒子的新 CU）\n",
    "        # 同时计算 CU 的密度\n",
    "        df_X_target = pd.DataFrame(self.X_train)\n",
    "\n",
    "        new_arrCU_start_points = None  # 编码单元起始点列表\n",
    "        new_arrCU_dL = None  # arrCU_start_points 对应位置的编码单元的边长 `dL`\n",
    "        new_arrCU_is_enable = None  # arrCU_start_points 对应位置的编码单元是否启用，True 代表启用，False 代表不启用\n",
    "        new_arrCU_final_target = None  # arrCU_start_points 对应位置的编码单元的最终预测类别（-1 代表无类别）\n",
    "        new_arrCU_force_infection = None  # arrCU_start_points 对应位置的编码单元的感染力度 (force of infection)\n",
    "\n",
    "        for i in range(self.arrCU_start_points.shape[0]):\n",
    "            if not self.arrCU_is_enable[i]:\n",
    "                continue\n",
    "            dL = self.arrCU_dL[i]\n",
    "            start_point = np.array(self.arrCU_start_points[i])\n",
    "            end_point = np.array(start_point + dL)\n",
    "\n",
    "            # 计算该单元中粒子的数量\n",
    "            tmp_s_is_X_in_CU = ((df_X_target > start_point) & (df_X_target < end_point)).all(axis=1)  # all代表按照y周判断是否这一行都为 True（也就是 point 每个对应维度都符合），返回对应位置为 True/False 的 pd.Series\n",
    "            num_point_in_CU = tmp_s_is_X_in_CU[tmp_s_is_X_in_CU == True].count()  # 该单元中粒子的数量\n",
    "            target_CU = None  # 编码单元的类别\n",
    "            density = None  # 密度（感染力度）\n",
    "\n",
    "            # CU 中无粒子\n",
    "            if 0 == num_point_in_CU:\n",
    "                density = 0.0\n",
    "                target_CU = self.CUType.EMPTY_CU.value\n",
    "            else:\n",
    "                density = num_point_in_CU / (dL ** self.N_train)\n",
    "                target_CU = self.arrCU_final_target[i]\n",
    "\n",
    "            # 第一个 enable 的 CU（也就是初始化 new_arr）\n",
    "            if new_arrCU_is_enable is None:\n",
    "                new_arrCU_start_points = np.array([self.arrCU_start_points[i]])\n",
    "                new_arrCU_dL = np.array(self.arrCU_dL[i])\n",
    "                new_arrCU_is_enable = np.array(self.arrCU_is_enable[i])\n",
    "                new_arrCU_final_target = np.array(target_CU)\n",
    "                new_arrCU_force_infection = np.array(density)\n",
    "                continue\n",
    "\n",
    "            new_arrCU_start_points = np.vstack([new_arrCU_start_points, np.array(self.arrCU_start_points[i])])\n",
    "            new_arrCU_dL = np.append(new_arrCU_dL, self.arrCU_dL[i])\n",
    "            new_arrCU_is_enable = np.append(new_arrCU_is_enable, self.arrCU_is_enable[i])\n",
    "            new_arrCU_final_target = np.append(new_arrCU_final_target, target_CU)\n",
    "            new_arrCU_force_infection = np.append(new_arrCU_force_infection, density)\n",
    "\n",
    "        del self.arrCU_start_points\n",
    "        del self.arrCU_dL\n",
    "        del self.arrCU_is_enable\n",
    "        del self.arrCU_final_target\n",
    "        del self.arrCU_force_infection\n",
    "\n",
    "        self.arrCU_start_points = new_arrCU_start_points\n",
    "        self.arrCU_dL = new_arrCU_dL\n",
    "        self.arrCU_is_enable = new_arrCU_is_enable\n",
    "        self.arrCU_final_target = new_arrCU_final_target\n",
    "        self.arrCU_force_infection = new_arrCU_force_infection\n",
    "\n",
    "    def pre_split(self):\n",
    "        \"\"\"\n",
    "        预分割阶段\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 预分割阶段\n",
    "        current_index = 0\n",
    "        while current_index < self.arrCU_start_points.shape[0]:\n",
    "            self.arr_checker()\n",
    "\n",
    "            # 如果当前 CU 已经废弃（disable），那么就没有再对他进行处理的意义了\n",
    "            if not self.arrCU_is_enable[current_index]:\n",
    "                current_index += 1\n",
    "                continue\n",
    "\n",
    "            # 如果当前 CU 启用，但是已经有了最终类别\n",
    "            if self.arrCU_is_enable[current_index] and self.arrCU_final_target[current_index] != self.CUType.NOT_FINAL_CU.value:\n",
    "                current_index += 1\n",
    "                continue\n",
    "\n",
    "            cur_target = self.is_CU_need_split(arr1d_start_points=self.arrCU_start_points[current_index],\n",
    "                                               dL=self.arrCU_dL[current_index])\n",
    "            print(f'[INFO] CUC.fit(): current_index: {current_index} \\t cur_target: {cur_target}')\n",
    "\n",
    "            if cur_target == self.CUType.NOT_FINAL_CU.value:\n",
    "                self.split_CU_and_update2arrCU(index_start_points=current_index)\n",
    "            else:\n",
    "                self.arrCU_is_enable[current_index] = True\n",
    "                self.arrCU_final_target[current_index] = cur_target\n",
    "                if self.N_train == 2 and self.is_draw_2D:\n",
    "                    self.draw_2d(color_map=self.color_map, pic_save_path=self.pic_save_path)\n",
    "\n",
    "            current_index += 1\n",
    "            # print(f'\\n>>>>>>>>>>>>>>>> 预分割阶段 {current_index}')\n",
    "            # res = pd.concat([pd.DataFrame(self.arrCU_start_points),\n",
    "            #                  pd.Series(self.arrCU_is_enable),\n",
    "            #                  pd.Series(self.arrCU_dL),\n",
    "            #                  pd.Series(self.arrCU_final_target)], axis=1)\n",
    "            # res.columns = ('x', 'y', 'is_enable', 'dL', 'target')\n",
    "            # print(res)\n",
    "\n",
    "    def refinement_split(self, num: int) -> None:\n",
    "        \"\"\"\n",
    "        细化分割\n",
    "        :param num:细化分割的次数\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.arr_checker()  # 执行数组长度一致性检查\n",
    "\n",
    "        for run_time in range(num):\n",
    "            # 对每个 enable 的 CU 进行细化分割\n",
    "            for i in range(self.arrCU_start_points.shape[0]):\n",
    "                if self.arrCU_is_enable[i] is False:\n",
    "                    continue\n",
    "                self.split_CU_and_update2arrCU(index_start_points=i)\n",
    "\n",
    "    def draw_2d(self, color_map, pic_save_path=None) -> None:\n",
    "        \"\"\"\n",
    "        绘制 2D 图形\n",
    "        :param color_map:\n",
    "        :param pic_save_path:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        color_map = np.array(color_map)\n",
    "        if color_map.shape[0] != self.N_train:\n",
    "            raise ValueError('\\n[CUC-ERROR] color_map.shape[0] != self.N_train')\n",
    "\n",
    "        plt.figure(figsize=(5, 5))\n",
    "\n",
    "        # 绘制点\n",
    "        tmp_data = pd.concat([pd.DataFrame(self.X_train), pd.Series(self.y_train)], axis=1)\n",
    "        tmp_data.columns = ('x', 'y', 'target')\n",
    "        for target in np.unique(self.y_train):\n",
    "            plt.scatter(tmp_data[tmp_data['target'] == target].values[:, 0],\n",
    "                        tmp_data[tmp_data['target'] == target].values[:, 1], c=color_map[target], s=5)\n",
    "\n",
    "        for i in range(self.arrCU_start_points.shape[0]):\n",
    "            target = self.arrCU_final_target[i]\n",
    "            # 如果当前 CU 不是最终的，或者是 disable 的，那么没有绘制的必要\n",
    "            if (target == self.CUType.NOT_FINAL_CU.value) or (self.arrCU_is_enable[i] is False):\n",
    "                continue\n",
    "\n",
    "            start_points = self.arrCU_start_points[i]\n",
    "            dL = self.arrCU_dL[i]\n",
    "            t_x_block = [start_points[0], start_points[0] + dL, start_points[0] + dL, start_points[0]]\n",
    "            t_y_block = [start_points[1], start_points[1],      start_points[1] + dL, start_points[1] + dL]\n",
    "\n",
    "            plt.plot(t_x_block, t_y_block, c='black')  # 黑色边框\n",
    "            if self.CUType.EMPTY_CU.value == target:\n",
    "                plt.fill(t_x_block, t_y_block, c='grey', alpha=0.2)\n",
    "            else:\n",
    "                plt.fill(t_x_block, t_y_block, c=color_map[target], alpha=0.2)\n",
    "            plt.title(f'Splitting process in CUC\\n(splits count {self.split_count})')\n",
    "            plt.ylabel('y')\n",
    "            plt.xlabel('x')\n",
    "            plt.axis('equal')  # x、y 单位长度等长\n",
    "\n",
    "        self.draw_count += 1\n",
    "        if pic_save_path is not None:\n",
    "            plt.savefig(f'{pic_save_path}-{self.draw_count}.png')\n",
    "        plt.show()\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"编码单元分类器的估计器（estimator）\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): 特征值\n",
    "            y (np.ndarray): 目标值\n",
    "\n",
    "        Raises:\n",
    "            ValueError: _description_\n",
    "        \"\"\"\n",
    "        # 如果特征值和目标值维度相等\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f'[CUC-ERROR] X.shape != y.shape: X.shape is {X.shape[0]}, y.shape is {y.shape[0]}')\n",
    "\n",
    "        # =================================== 初始化 CUC 配置参数 ===================================\n",
    "        self.N_train = X.shape[1]\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "        self.df_train = pd.concat([pd.DataFrame(self.X_train), pd.Series((self.y_train), name='target')], axis=1)\n",
    "\n",
    "        self.CU_min = X.min()\n",
    "        self.CU_max = X.max()\n",
    "\n",
    "        # 目标值转为数值类型\n",
    "        self.transfer_LabelEncoder = LabelEncoder()\n",
    "        self.y_train = np.array(self.transfer_LabelEncoder.fit_transform(y=y), dtype=np.int)\n",
    "\n",
    "        # 初始化 CU 相关 ndarray\n",
    "        self.arrCU_start_points = np.full(shape=(1, self.N_train), fill_value=self.CU_min)  # 将初始化中的 0.0 替换为编码单元的起始点\n",
    "        self.arrCU_dL = np.array([self.CU_max - self.CU_min])\n",
    "        self.arrCU_is_enable = np.array([True])\n",
    "        self.arrCU_final_target = np.array([self.CUType.NOT_FINAL_CU.value], dtype=np.int)\n",
    "        self.arrCU_force_infection = np.array([np.nan])\n",
    "        # =========================================================================================\n",
    "\n",
    "        # ========================================= 预分割 =========================================\n",
    "        self.pre_split()\n",
    "        self.remove_disable_points()\n",
    "        # =========================================================================================\n",
    "\n",
    "        print('\\n>>>>>>>>>>>>>>>> 完成预分割后的arr结果')\n",
    "        res = pd.concat([pd.DataFrame(self.arrCU_start_points),\n",
    "                         pd.Series(self.arrCU_is_enable),\n",
    "                         pd.Series(self.arrCU_dL),\n",
    "                         pd.Series(self.arrCU_final_target),\n",
    "                         pd.Series(self.arrCU_force_infection)], axis=1)\n",
    "        res.columns = ('x', 'y', 'is_enable', 'dL', 'target', 'force_infection')\n",
    "        print(res)\n",
    "\n",
    "        # ========================================= 细化分割 =========================================\n",
    "        self.refinement_split(num=self.num_refinement_splits)\n",
    "        self.remove_disable_points()\n",
    "        if self.N_train == 2 and self.is_draw_2D:\n",
    "            self.draw_2d(color_map=self.color_map, pic_save_path=self.pic_save_path)\n",
    "\n",
    "        print('\\n>>>>>>>>>>>>>>>> 完成细化分割后的arr结果')\n",
    "        res = pd.concat([pd.DataFrame(self.arrCU_start_points),\n",
    "                         pd.Series(self.arrCU_is_enable),\n",
    "                         pd.Series(self.arrCU_dL),\n",
    "                         pd.Series(self.arrCU_final_target),\n",
    "                         pd.Series(self.arrCU_force_infection)], axis=1)\n",
    "        res.columns = ('x', 'y', 'is_enable', 'dL', 'target', 'force_infection')\n",
    "        print(res)\n",
    "        # =========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = CodingUnitClassifier(num_refinement_splits=1, is_draw_2D=True, color_map=('blue', 'red'), pic_save_path='./output/CUC')\n",
    "estimator.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([pd.DataFrame(estimator.arrCU_start_points), \n",
    "             pd.Series(estimator.arrCU_is_enable), \n",
    "             pd.Series(estimator.arrCU_dL)], axis=1)\n",
    "res.columns = ('x', 'y', 'is_enable', 'dL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
